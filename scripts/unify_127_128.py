#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
127.csv/128.csvã‚’çµ±ä¸€ä¿®æ­£
1. ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’128.csvã«çµ±ä¸€ï¼ˆidãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é™¤å¤–ï¼‰
2. banksãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰éŠ€è¡Œåã®ã¿ã‚’æŠ½å‡ºã€è¤‡æ•°ã‚ã‚‹å ´åˆã¯ãƒ»ã§é€£çµ
3. contactUrlã® https://valuesearch.nikkei ã§å§‹ã¾ã‚‹URLã‚’å‰Šé™¤
"""

import csv
import json
import re
import sys
import ast

csv.field_size_limit(sys.maxsize)

def extract_bank_names(banks_str):
    """banksãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‹ã‚‰éŠ€è¡Œåã®ã¿ã‚’æŠ½å‡º"""
    if not banks_str or banks_str.strip() == '':
        return ''
    
    banks_str = banks_str.strip()
    
    # JSON/dictå½¢å¼ã®å ´åˆ
    if banks_str.startswith('{'):
        try:
            # ã¾ãšJSONã¨ã—ã¦è©¦ã™
            try:
                data = json.loads(banks_str)
            except:
                # JSONã§ãƒ€ãƒ¡ãªã‚‰Pythonã®dictå½¢å¼ã¨ã—ã¦è§£æ
                data = ast.literal_eval(banks_str)
            bank_names = []  # setã§ã¯ãªãlistã§é †åºã‚’ä¿æŒ
            
            # tablesé…åˆ—ã‹ã‚‰titleã‚’è§£æ
            if isinstance(data, dict) and 'tables' in data:
                for table in data['tables']:
                    if 'title' in table:
                        title = table['title']
                        # ä¸è¦ãªæ–‡å­—åˆ—ã‚’é™¤å»
                        title = re.sub(r'å€Ÿå…¥å…ˆé‡‘èæ©Ÿé–¢å', '', title)
                        title = re.sub(r'å€Ÿå…¥é‡‘ç·åˆè¨ˆ', '', title)
                        title = re.sub(r'é‡‘èæ©Ÿé–¢åˆ¥å€Ÿå…¥é‡‘', '', title)
                        title = re.sub(r'ä¸æ˜åˆ†', '', title)
                        title = title.strip()
                        
                        # æ®‹ã£ãŸæ–‡å­—åˆ—ã‹ã‚‰éŠ€è¡Œåã‚’æŠ½å‡º
                        # ã‚¹ãƒšãƒ¼ã‚¹ã§åˆ†å‰²
                        words = re.split(r'\s+', title)
                        for word in words:
                            # éŠ€è¡Œåã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ã‹
                            if any(kw in word for kw in ['éŠ€è¡Œ', 'ä¿¡é‡‘', 'ä¿¡çµ„', 'ãƒãƒ³ã‚¯', 'é‡‘åº«', 'è¾²å”', 'JA', 'ä¿¡ç”¨é‡‘åº«', 'ä¿¡ç”¨çµ„åˆ']):
                                # éŠ€è¡Œã‚³ãƒ¼ãƒ‰ï¼ˆæ•°å­—4æ¡ï¼‰ã‚’é™¤å»
                                word = re.sub(r'^\d{4}\s*', '', word)
                                word = word.strip()
                                
                                # æœ€ä½3æ–‡å­—ä»¥ä¸Šã§ã€é‡è¤‡ã—ãªã„å ´åˆã®ã¿è¿½åŠ 
                                if word and len(word) >= 3 and word not in bank_names:
                                    bank_names.append(word)
            
            if bank_names:
                # ãƒ»ã§é€£çµ
                return 'ãƒ»'.join(bank_names)
        except Exception as e:
            # JSON ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã«ã™ã‚‹
            return ''
    
    # ãƒªã‚¹ãƒˆå½¢å¼ã®æ–‡å­—åˆ—ã®å ´åˆ ['éŠ€è¡Œå']
    if banks_str.startswith('['):
        banks_str = banks_str.replace('[', '').replace(']', '').replace("'", '').replace('"', '')
        # è¤‡æ•°éŠ€è¡ŒãŒã‚ã‚‹å ´åˆ
        banks = []
        for bank in banks_str.split(','):
            bank = bank.strip()
            if not bank:
                continue
            # éŠ€è¡Œã‚³ãƒ¼ãƒ‰é™¤å»
            bank = re.sub(r'^\d{4}\s+', '', bank)
            bank = bank.strip()
            if bank and len(bank) >= 3:
                banks.append(bank)
        return 'ãƒ»'.join(banks)
    
    # ãã®ä»–ã®å ´åˆï¼ˆãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼‰
    # éŠ€è¡Œã‚³ãƒ¼ãƒ‰é™¤å»
    banks_str = re.sub(r'^\d{4}\s+', '', banks_str)
    return banks_str.strip()

def clean_contact_url(url_str):
    """contactUrlã‹ã‚‰ valuesearch.nikkei ã®URLã‚’å‰Šé™¤"""
    if not url_str:
        return ''
    
    url = url_str.strip()
    
    # https://valuesearch.nikkei ã§å§‹ã¾ã‚‹å ´åˆã¯å‰Šé™¤
    if url.startswith('https://valuesearch.nikkei'):
        return ''
    
    return url

def unify_csv(input_file, output_file, target_headers):
    """CSVã‚’çµ±ä¸€å½¢å¼ã«å¤‰æ›"""
    
    rows_processed = 0
    banks_cleaned = 0
    urls_cleaned = 0
    
    with open(input_file, 'r', encoding='utf-8') as infile, \
         open(output_file, 'w', encoding='utf-8', newline='') as outfile:
        
        reader = csv.DictReader(infile)
        writer = csv.DictWriter(outfile, fieldnames=target_headers, extrasaction='ignore')
        writer.writeheader()
        
        for row in reader:
            rows_processed += 1
            
            new_row = {}
            
            # å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆidãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯é™¤å¤–ï¼‰
            for field in target_headers:
                new_row[field] = row.get(field, '')
            
            # banksãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³
            if new_row.get('banks'):
                original = new_row['banks']
                cleaned = extract_bank_names(original)
                # JSONå½¢å¼ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆã¯ç©ºã«ã™ã‚‹
                if cleaned.startswith('{'):
                    cleaned = ''
                if cleaned != original:
                    new_row['banks'] = cleaned
                    banks_cleaned += 1
            
            # contactUrlã‚’ã‚¯ãƒªãƒ¼ãƒ³
            if new_row.get('contactUrl'):
                original = new_row['contactUrl']
                cleaned = clean_contact_url(original)
                if cleaned != original:
                    new_row['contactUrl'] = cleaned
                    urls_cleaned += 1
            
            writer.writerow(new_row)
    
    print(f"âœ… {input_file} â†’ {output_file}")
    print(f"   å‡¦ç†è¡Œæ•°: {rows_processed}")
    print(f"   banksä¿®æ­£: {banks_cleaned}")
    print(f"   contactUrlå‰Šé™¤: {urls_cleaned}")

if __name__ == '__main__':
    print("ğŸ”§ 127.csv/128.csv çµ±ä¸€ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    print("   1. ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’128.csvå½¢å¼ã«çµ±ä¸€ï¼ˆidãªã—ï¼‰")
    print("   2. banksã‚’éŠ€è¡Œåã®ã¿ã«ï¼ˆãƒ»ã§é€£çµï¼‰")
    print("   3. contactUrlã® valuesearch.nikkei ã‚’å‰Šé™¤")
    print("")
    
    # 128.csvã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’åŸºæº–ã¨ã™ã‚‹ï¼ˆidãªã—ï¼‰
    target_headers = [
        'name', 'nameEn', 'corporateNumber', 'prefecture', 'address', 'industry',
        'capitalStock', 'revenue', 'latestProfit', 'employeeCount', 'issuedShares',
        'established', 'fiscalMonth', 'listing', 'representativeName', 'businessDescriptions',
        'companyUrl', 'contactUrl', 'banks', 'affiliations', 'overview', 'history',
        'totalAssets', 'totalLiabilities', 'netAssets', 'revenueFromStatements', 'operatingIncome'
    ]
    
    # 127.csv
    print("ğŸ“„ 127.csv ã‚’çµ±ä¸€å½¢å¼ã«å¤‰æ›ä¸­...")
    unify_csv('./csv/127.csv', './csv/127_unified.csv', target_headers)
    print("")
    
    # 128.csv
    print("ğŸ“„ 128.csv ã‚’çµ±ä¸€å½¢å¼ã«å¤‰æ›ä¸­...")
    unify_csv('./csv/128.csv', './csv/128_unified.csv', target_headers)
    print("")
    
    print("ğŸ‰ å®Œäº†ï¼")
    print("   çµ±ä¸€å¾Œ: csv/127_unified.csv, csv/128_unified.csv")
    print("")
    print("ğŸ“Œ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   mv csv/127_unified.csv csv/127.csv")
    print("   mv csv/128_unified.csv csv/128.csv")

